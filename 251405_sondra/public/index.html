<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>revealjs</title>

		<meta name="description" content="2024">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides" style="font-size:40px">

				<!-- New slide -->
				<section style="font-size:40px">
					<h3 style="color: #ffffff;">SONDRA WORKSHOP 2025</h3>
					<h3 style="color: #ffffff;">https://sondra2025.sciencesconf.org/</h3><br>
					<h2 style="color: #a8d2ff;">Research at NUS on optical and SAR data registration<br>using deep learning models </h2><br>
					<div style="color: #ffffff;">Michael Dell'aiera, Koen Mouthaan</div>

					<div class="container" style="margin:10px 120px 10px 120px">
						<div class="title" style="border-radius: 10px; background-color:rgb(255, 255, 255, 1);">
							<img src="resources/logos/logo_nus.png" style="height: 100px;"/>
							<img src="resources/logos/logo_sondra.png" style="height: 100px;"/>
						</div>
					</div>

					<div style="color: #ffffff;">May 14th 2025</div>
					<div style="color: #ffffff;">mda@nus.edu.sg</div>
				</section>

				<!-- New slide -->
				<section>
					<h2 class='slide-title' style="color:#9ecdff" align="left">Introduction</h2><hr>

					<p data-markdown style="text-align: left">
						Postdoc at NUS, Singapore on Optical and SAR data fusion using deep learning techniques
						<br>
						PhD work on deep learning applied to astrophysics (CTAO project)
					</p>

					<br>
					<div style="display: flex;">
						<div style="width: 1%"></div>
						<div style="width: 24%">
							Topic 1<br>SAR and Optical Registration
							<hr>
							<figure>
								<img style="width: 100%" src="resources/registration.png">
							</figure>
							<p style="color: red;">&rarr; Topic of the day</p>
						</div>
						<div style="width: 2%"></div>
						<div style="width: 24%">
							Topic 2<br>Optical-guided SAR Despeckling
							<hr>
							<figure>
								<img style="width: 100%" src="resources/despeckling.gif">
							</figure>
						</div>
						<div style="width: 2%"></div>
						<div style="width: 24%">
							Topic 3<br>Target Detection in SAR Images
							<hr>
							<figure>
								<img style="width: 100%" src="resources/target_detection.png">
							</figure>
							In collabaration with<br>Xu Xiaowo (NUS)
						</div>
						<div style="width: 2%"></div>
						<div style="width: 24%">
							Topic 4<br>Free Topics to Explore in Infomation Fusion / SAR
							<hr>
							<ul>
								<li>Scintillations, following the works of Harsha (and now Hugo)</li>
								<li>...</li>
							</ul>
						</div>
						<div style="width: 1%"></div>
				</section>
				
				<!-- New slide -->
				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Definition and contextualisation</p></h2><hr>

					<div style="display: flex;">
						<div style="width: 45%" align="left">
							<div>
								Image registration = Process of aligning two or more images, i.e. find the transformation that link them.

								<ul>
									<li>Wildly use in Computer Vision (medical, etc)</li>
									<li>SAR and optical: Geometric and radiometric differences</li>
									<li>Often 1st step before information fusion</li>
									<li>Must be robust to scale, rotation, translation, occlusion, noise, etc.</li>
								</ul>
								<br><br>
								<u>Objective of the presentation:</u>
								<ul>
									<li>Evaluate some popular deep learning methods</li>
									<li>Assess domain adaptation</li>
								</ul>
							</div>
						</div>
						<div style="width: 10%"></div>
						<div style="width: 45%" align="left">
							<figure>
								<img style="width: 80%" src="resources/image_registration_sift.png">
								<figcaption>Fig. Optical image registration using feature points</figcaption>
							</figure>
						</div>
					</div>

					<hr>
					<p data-markdown style="text-align: left; font-size:20px">
						[A Survey on SAR and Optical Satellite Image Registration.](https://www.mdpi.com/2072-4292/15/3/850)
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">State-of-the-art of Image Registration (Non-exhaustive)</p></h2><hr>

					<object type="image/svg+xml" data="resources/sota_registration.drawio.svg" width="100%"></object>

					<div style="display: flex;">
						<div style="width: 33%" align="left">
							Area-Based<br>
							<ul>
								<li>No cross-modality</li>
							</ul>
						</div>
						<div style="width: 33%" align="left">
							Hand-designed<br>
							<ul>
								<li>No cross-modality</li>
							</ul>
						</div>
						<div style="width: 33%" align="left">
							Deep leaning-based<br>
							<ul>
								<li>Tailored filters</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Workflow</p></h2><hr>
					

				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Image-to-image Translation</p></h2><hr>

					<div style="display: flex;">
						<div style="width: 50%" align="left">
							<ul>
								<li><em>Definition -</em> Image-to-image translation = Converting an image from one domain to another
									<ul>
										<li>What? Optical to SAR, SAR to optical, etc.</li>
										<li>Why? Compute metrics on images from different domains is difficult</li>
										<li>How? Popular methods are CycleGAN, pix2pix</li>
									</ul>
								</li>

								<figure align="center">
									<img style="width: 60%" src="resources/methodology.png">
									<figcaption>Fig. Image registration with two different domains</figcaption>
								</figure>
							</ul>
						</div>
						<div style="width: 50%">
							<figure align="center">
								<img style="width: 100%" src="resources/image_translation_example.png">
								<figcaption>Fig. CycleGAN image translation examples</figcaption>
							</figure>
						</div>
					</div>

					<hr>
					<p data-markdown style="text-align: left; font-size:20px">
						[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

						[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004)
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Domain adaptation</p></h2><hr>

					<p data-markdown style="text-align: left;">
						Def : Transfer knowledge from a source domain to a target domain
						* Idea: we do not need all the information from the distributions
						* Unpaired images
						* Very wide state-of-the-art
					</p>
					
					<div style="display: flex;">
						<div style="width: 50%">
							<figure align="center">
								<img style="width: 100%" src="resources/domain_adaptation_classification.png">
								<figcaption>Fig. Domain Adaptation in Classification</figcaption>
							</figure>
						</div>
						<div style="width: 50%">
							<figure align="center">
								<img style="width: 100%" src="resources/domain_adaptation_regression.png">
								<figcaption>Fig. Domain Adaptation in Regression</figcaption>
							</figure>
						</div>
					</div>

					<hr>
					<p data-markdown style="text-align: left; font-size:20px">
						[Unsupervised Domain Adaptation for Regression Using Dictionary Learning, Dhaini et al., 2023](https://normandie-univ.hal.science/hal-04012551v1/file/Unsupervised_Domain_Adaptation_Using_Dictionary_Learning__HAL_.pdf)
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Domain Adversarial Neural Network (DANN)</p></h2><hr>
					
					<div style="display: flex;">
						<div style="width: 40%">
							<p data-markdown style="text-align: left;">
								* One of the most popular method
								* Introduces Gradient Reversal Layer (GRL) and domain discriminator to compute an estimate of the $\mathcal{A}$-distance
								* Train an encoder to extract domain-invariant features
								* $\mathcal{H}_y \\subseteq \mathcal{H}_d$
								* Multi-task balancing
							</p>
						</div>
						<div style="width: 60%">
							<figure align="center">
								<img style="width: 100%" src="resources/dann.png">
								<figcaption>Fig. Architecture of the DANN</figcaption>
							</figure>
						</div>
					</div>

					<hr>
					<p data-markdown style="text-align: left; font-size:20px">
						[Domain-Adversarial Training of Neural Networks, Ganin et al., 2015](https://arxiv.org/abs/1505.07818)
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Superpoint</p></h2><hr>

					<div style="display: flex;">
						<div style="width: 50%">
							<figure align="center">
								<img style="width: 90%" src="resources/superpoint.png">
								<figcaption>Fig. Architecture of the SuperPoint</figcaption>
							</figure>
						</div>
						<div style="width: 50%">

						</div>
					</div>

					<hr>
					<p data-markdown style="text-align: left; font-size:20px">
						[SuperPoint: Self-Supervised Interest Point Detection and Description, DeTone et al., 2017](https://arxiv.org/abs/1712.07629)
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Preliminary Results (CycleGAN+SuperPoint)</p></h2><hr>
					

				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Preliminary Results (DANN+SuperPoint)</p></h2><hr>
					

				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Conclusion and Perspectives</p></h2><hr>
					
					<p data-markdown style="text-align: left">
						* Image translation methods "hallucinate", i.e. they create new features that are not present in the original image

						* Domain adaptation methods are difficult to train, especially adversarial methods

						&rarr; Wasserstein-DANN with Optimal Transport based distance computation

						* Other domain adaptation methods to explore, e.g. Optimal Transport

						&rarr; May 15th, SP.4: Optimal Transport for Radar Domain Adaptation, by Daniel Brooks 

						* Likelihood-free inference (likelihood-ratio estimation): Recasting a regression-style inference problem as a classification problem in order to sidestep the need for a likelihood ($\mathcal{H}_y \\subseteq \mathcal{H}_d$)

						* Test on different resolutions
					</p>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Annex: CycleGAN Architecture</p></h2><hr>

					<figure>
						<img style="width: 85%" src="resources/cyclegan.png">
					</figure>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Annex: Despeckling</p></h2><hr>

					<figure>
						<img style="width: 70%" src="resources/despeckling.png">
					</figure>
				</section>

				<section>
					<h2 class='slide-title' align="left"><p style="color:#9ecdff">Notes</p></h2><hr>
				</section>
			</div>
		</div>

		<!-- To add color to code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				slideNumber: true,
				progress: true,
				width: 1920,
  				height: 1080,
				center: false,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ],
			});
		</script>
	</body>
</html>
